{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "810c3de4-38cd-4a6d-9bbb-0f0d973d8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1701e972-3dd4-46f1-9026-77e27eb45b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9614e4d1-c2a1-4b2f-bf60-1f3066d16fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a909071-7191-44a8-b5e8-86dab2f941c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_EAR(eye_landmarks):\n",
    "    A = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    B = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    C = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    EAR = (A + B) / (2.0 * C)\n",
    "    return EAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ff76dad-ae7c-4dcb-b48d-19a3e03fe726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_head_direction(landmarks):\n",
    "    nose_tip = np.array(landmarks[1])\n",
    "    left_eye = np.mean(landmarks[2:4], axis=0)\n",
    "    right_eye = np.mean(landmarks[5:7], axis=0)\n",
    "    face_vector = right_eye - left_eye\n",
    "    direction = 'Center'\n",
    "    if face_vector[0] > 0:\n",
    "        direction = 'Right'\n",
    "    elif face_vector[0] < 0:\n",
    "        direction = 'Left'\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0e35744-e885-4f3e-8e0b-375fb8baef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_looking_down(landmarks):\n",
    "    nose_tip = np.array(landmarks[1])\n",
    "    chin = np.array(landmarks[152])  # 턱의 랜드마크\n",
    "    vertical_distance = nose_tip[1] - chin[1]\n",
    "    \n",
    "    if vertical_distance < 20:  # 고개가 많이 숙여졌다면\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63ac3d07-922e-48a5-9381-291688259df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_looking_at_phone(landmarks):\n",
    "    left_eye = [landmarks[i] for i in [362, 385, 387, 263, 373, 380]]\n",
    "    right_eye = [landmarks[i] for i in [33, 160, 158, 133, 153, 144]]\n",
    "    \n",
    "    eye_center = np.mean([landmarks[468], landmarks[473]], axis=0)  # 눈동자 중심\n",
    "    eye_bottom = (left_eye[2][1] + right_eye[2][1]) / 2  # 눈 아래쪽 랜드마크의 Y좌표\n",
    "    \n",
    "    if eye_center[1] > eye_bottom:  # 눈동자가 아래쪽을 보고 있는 경우\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3da4cbfc-9c31-4b74-9708-e514d87d9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 눈 깜빡임 및 졸음 감지 파라미터\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 48\n",
    "blink_counter = 0\n",
    "drowsy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d71e045-ec3a-4d04-8bad-8be98e9c1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6648566b-e03b-494a-a551-a29a76286b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe face mesh 객체 생성\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # 비디오 프레임 읽기\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # 프레임이 비어 있는지 확인\n",
    "        if not ret or frame is None:\n",
    "            print(\"프레임을 읽을 수 없습니다.\")\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            rgb_frame = cv2.cvtColor(roi_color, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(rgb_frame)\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    height, width, _ = roi_color.shape\n",
    "                    landmarks = [(int(pt.x * width), int(pt.y * height)) for pt in face_landmarks.landmark]\n",
    "\n",
    "                    left_eye_landmarks = [landmarks[i] for i in [362, 385, 387, 263, 373, 380]]\n",
    "                    right_eye_landmarks = [landmarks[i] for i in [33, 160, 158, 133, 153, 144]]\n",
    "\n",
    "                    left_EAR = calculate_EAR(left_eye_landmarks)\n",
    "                    right_EAR = calculate_EAR(right_eye_landmarks)\n",
    "                    EAR = (left_EAR + right_EAR) / 2.0\n",
    "\n",
    "                    face_direction = estimate_head_direction(landmarks)\n",
    "\n",
    "                    if EAR < EYE_AR_THRESH:\n",
    "                        blink_counter += 1\n",
    "                    else:\n",
    "                        if blink_counter >= EYE_AR_CONSEC_FRAMES:\n",
    "                            drowsy = True\n",
    "                        blink_counter = 0\n",
    "\n",
    "                    if is_looking_down(landmarks) and is_looking_at_phone(landmarks):\n",
    "                        cv2.putText(frame, \"넌 지금 휴대폰을 보고 있다.\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    elif drowsy:\n",
    "                        cv2.putText(frame, \"다 졸았니?\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(roi_color, face_landmarks, mp_face_mesh.FACEMESH_TESSELATION)\n",
    "\n",
    "        cv2.imshow('Eyee Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
