{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf6b6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "746d1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, img_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Load dataset from directory.\n",
    "\n",
    "    Args:\n",
    "    - data_dir (str): Path to the directory containing the dataset.\n",
    "    - img_size (tuple): Size to resize the images.\n",
    "\n",
    "    Returns:\n",
    "    - images (list): List of resized images.\n",
    "    - labels (list): List of corresponding labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, category in enumerate(['Closed_Eyes', 'Open_Eyes']):\n",
    "        category_dir = os.path.join(data_dir, category)\n",
    "        for img_name in os.listdir(category_dir):\n",
    "            img_path = os.path.join(category_dir, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "937a23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_dir, test_size=0.2, img_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Prepare dataset for training and testing.\n",
    "\n",
    "    Args:\n",
    "    - data_dir (str): Path to the directory containing the dataset.\n",
    "    - test_size (float): Percentage of the dataset to use for testing.\n",
    "    - img_size (tuple): Size to resize the images.\n",
    "\n",
    "    Returns:\n",
    "    - train_set (tuple): Tuple containing train images and labels.\n",
    "    - test_set (tuple): Tuple containing test images and labels.\n",
    "    \"\"\"\n",
    "    # 데이터 로드\n",
    "    images, labels = load_data(data_dir, img_size)\n",
    "    \n",
    "    # 훈련 데이터, 테스트 데이터 분리\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # 이미지 정규화\n",
    "    train_images = train_images.astype('float32') / 255.0\n",
    "    test_images = test_images.astype('float32') / 255.0\n",
    "    \n",
    "    return (train_images, train_labels), (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e37500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 제작\n",
    "(train_images, train_labels), (test_images, test_labels) = prepare_data(r'C:\\Users\\impra\\Desktop\\2024_first_semester\\AIUI\\Stracker\\eye-detection-model\\jiwon\\drowsy_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd9034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m918/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 565ms/step - accuracy: 0.9393 - loss: 2.7588 - val_accuracy: 0.9986 - val_loss: 0.3968\n",
      "Epoch 2/2\n",
      "\u001b[1m918/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 533ms/step - accuracy: 0.9974 - loss: 0.2964 - val_accuracy: 0.9986 - val_loss: 0.1215\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 914ms/step - accuracy: 0.9982 - loss: 0.1213\n",
      "Test Loss: 0.12145296484231949, Test Accuracy: 0.9986376166343689\n"
     ]
    }
   ],
   "source": [
    "# Resnet50v2 모델 가지고 모델 제작\n",
    "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# ResNet50V2의 마지막 레이어 직전까지 고정\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 모델 구성 수정\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)  # 가중치 규제 적용\n",
    "x = Dropout(0.3)(x)  # 드롭아웃 추가\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# 새로운 모델 정의\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.00008), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(train_images, train_labels, batch_size=16, epochs=2, validation_data=(test_images, test_labels))\n",
    "\n",
    "# 모델 실행\n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2c69151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이티브 Keras 형식으로 모델 저장\n",
    "model.save('Improved_Resnet50v2_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
